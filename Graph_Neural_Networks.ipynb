{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph Neural Networks",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xwzy/from-colab/blob/master/Graph_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gBxcjRDEliK",
        "colab_type": "text"
      },
      "source": [
        "# Graph Neural Networks\n",
        "\n",
        "In this tutorial, we will explore the implementation of graph neural networks and investigate what representations these networks learn. Along the way, we'll see how PyTorch Geometric and TensorBoardX can help us with constructing and training graph models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwdncyH6CEZ9",
        "colab_type": "text"
      },
      "source": [
        "# Preliminaries: PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feCFN2K3Hcte",
        "colab_type": "text"
      },
      "source": [
        "We'll first demonstrate some essential features of PyTorch which we'll use throughout. PyTorch is a general machine learning library that allows us to dynamically define computation graphs which we'll use to describe our models and their training processes.\n",
        "\n",
        "We'll start by importing everything we need:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNtPXYKmCVow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import sklearn.metrics as metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7L1yNOAILmW",
        "colab_type": "text"
      },
      "source": [
        "We'll first download and load in a dataset (here the MNIST handwritten digits dataset) through the `DataLoader` utility:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M3Ckk-xEvXm",
        "colab_type": "code",
        "outputId": "64283c17-8c64-447c-d803-54df98292c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "## transformations\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "## download and load training dataset\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "## download and load testing dataset\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 9904128/9912422 [01:29<00:00, 87955.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 28%|██▊       | 8192/28881 [00:00<00:00, 48480.24it/s]\u001b[A\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 32768/1648877 [00:00<00:13, 117765.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 57344/1648877 [00:00<00:12, 125737.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 73728/1648877 [00:00<00:13, 116538.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 98304/1648877 [00:00<00:12, 124570.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 122880/1648877 [00:01<00:11, 130863.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 139264/1648877 [00:01<00:12, 119632.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 172032/1648877 [00:01<00:10, 136063.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█▏        | 188416/1648877 [00:01<00:16, 89250.62it/s] \u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 221184/1648877 [00:01<00:13, 106441.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 237568/1648877 [00:02<00:13, 105315.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 253952/1648877 [00:02<00:18, 76049.09it/s] \u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 294912/1648877 [00:02<00:13, 97586.59it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 311296/1648877 [00:02<00:13, 98237.71it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 327680/1648877 [00:02<00:11, 110473.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 344064/1648877 [00:03<00:16, 81460.00it/s] \u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 360448/1648877 [00:03<00:14, 88393.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 376832/1648877 [00:03<00:13, 91511.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 393216/1648877 [00:03<00:13, 93830.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 409600/1648877 [00:03<00:12, 98734.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 425984/1648877 [00:03<00:10, 111190.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 442368/1648877 [00:04<00:10, 112244.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 458752/1648877 [00:04<00:09, 123918.98it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 483328/1648877 [00:04<00:08, 134533.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 507904/1648877 [00:04<00:09, 119411.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 532480/1648877 [00:04<00:08, 127295.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 557056/1648877 [00:04<00:08, 132122.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 573440/1648877 [00:05<00:12, 87631.54it/s] \u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 589824/1648877 [00:05<00:11, 93256.82it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 606208/1648877 [00:05<00:17, 60498.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 622592/1648877 [00:06<00:18, 54493.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 630784/1648877 [00:06<00:17, 57524.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 647168/1648877 [00:06<00:15, 65678.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 663552/1648877 [00:06<00:13, 73056.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 679936/1648877 [00:06<00:12, 79340.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 704512/1648877 [00:07<00:10, 92254.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 729088/1648877 [00:07<00:10, 85667.83it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 761856/1648877 [00:07<00:08, 104035.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 778240/1648877 [00:07<00:07, 108866.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 794624/1648877 [00:07<00:07, 117908.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 819200/1648877 [00:08<00:08, 100611.55it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 843776/1648877 [00:08<00:07, 112748.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 860160/1648877 [00:08<00:07, 108438.58it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 876544/1648877 [00:08<00:09, 78940.26it/s] \u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 892928/1648877 [00:08<00:08, 84223.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 909312/1648877 [00:09<00:09, 78847.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 925696/1648877 [00:09<00:10, 66969.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "9920512it [01:40, 87955.80it/s]                             \n",
            "32768it [00:10, 48480.24it/s]                          \u001b[A\n",
            "\n",
            " 58%|█████▊    | 958464/1648877 [00:10<00:12, 54660.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 983040/1648877 [00:10<00:09, 67024.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 999424/1648877 [00:10<00:08, 74287.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 1015808/1648877 [00:10<00:07, 80461.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 1032192/1648877 [00:10<00:07, 85314.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▎   | 1048576/1648877 [00:10<00:06, 89946.08it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 1073152/1648877 [00:11<00:05, 100434.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 1097728/1648877 [00:11<00:05, 100262.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 1122304/1648877 [00:11<00:05, 93128.79it/s] \u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 1155072/1648877 [00:12<00:04, 99829.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 1171456/1648877 [00:12<00:04, 99678.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 1187840/1648877 [00:12<00:06, 72931.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 1204224/1648877 [00:12<00:06, 70892.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 1220608/1648877 [00:13<00:06, 62968.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 1228800/1648877 [00:13<00:09, 46290.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 1236992/1648877 [00:13<00:12, 32731.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 1245184/1648877 [00:13<00:11, 36489.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 1253376/1648877 [00:14<00:09, 39686.64it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 1261568/1648877 [00:14<00:09, 42284.65it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 1269760/1648877 [00:14<00:09, 40668.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 1277952/1648877 [00:14<00:08, 43039.74it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 1286144/1648877 [00:14<00:07, 49331.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 1294336/1648877 [00:14<00:06, 51864.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 1310720/1648877 [00:15<00:05, 58756.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 1327104/1648877 [00:15<00:04, 67012.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 1343488/1648877 [00:15<00:05, 59192.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 1359872/1648877 [00:15<00:04, 67125.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 1376256/1648877 [00:15<00:03, 74435.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 1392640/1648877 [00:16<00:02, 87445.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 1409024/1648877 [00:16<00:02, 83048.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▋ | 1425408/1648877 [00:16<00:02, 83435.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 1441792/1648877 [00:16<00:03, 62341.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 1466368/1648877 [00:17<00:02, 62785.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 1474560/1648877 [00:17<00:02, 58249.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 1482752/1648877 [00:17<00:02, 55378.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 1490944/1648877 [00:18<00:04, 33416.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 1499136/1648877 [00:18<00:04, 34488.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████▏| 1507328/1648877 [00:18<00:03, 37995.37it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 1523712/1648877 [00:18<00:02, 43479.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 1540096/1648877 [00:18<00:02, 52285.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 1556480/1648877 [00:19<00:01, 60956.75it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 1581056/1648877 [00:19<00:01, 64441.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 1605632/1648877 [00:19<00:00, 77736.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 1622016/1648877 [00:20<00:00, 57226.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 1630208/1648877 [00:20<00:00, 49381.95it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 1638400/1648877 [00:20<00:00, 29710.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|█████████▉| 1646592/1648877 [00:21<00:00, 28874.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "8192it [00:00, 48317.64it/s]            \u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8V5S0a4gaR3",
        "colab_type": "code",
        "outputId": "f13aad2a-e69a-42cf-c834-b5efbefb0035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(len(trainset))\n",
        "print(trainset[10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.1647, 0.4627, 0.8588, 0.6510, 0.4627,\n",
            "          0.4627, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.4039, 0.9490, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0706, 0.9098, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9333, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.4078, 0.9569, 0.9961, 0.8784, 0.9961,\n",
            "          0.9961, 0.9961, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9961, 0.8235, 0.9961,\n",
            "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.8078, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.8196, 0.9961,\n",
            "          0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.5373, 0.9922, 0.9961,\n",
            "          0.9961, 0.9961, 0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.1569, 0.8392, 0.9804, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.3176, 0.9686, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.5725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.4314, 0.9647, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.3490, 0.3490, 0.3647,\n",
            "          0.9412, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
            "          0.5020, 0.9961, 0.8588, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n",
            "          0.9961, 0.9961, 0.8392, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5412,\n",
            "          0.9961, 0.9961, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.6941,\n",
            "          0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.9412,\n",
            "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9961,\n",
            "          0.8431, 0.2471, 0.1412, 0.0000, 0.2000, 0.3490, 0.8078, 0.9961,\n",
            "          0.9961, 0.5451, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.7725,\n",
            "          0.9961, 0.9961, 0.8706, 0.7059, 0.9451, 0.9961, 0.9961, 0.9922,\n",
            "          0.8353, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490,\n",
            "          0.4118, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9255,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0275, 0.4588, 0.4588, 0.6471, 0.9961, 0.9961, 0.9373, 0.1961,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]]), 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1jlPrOmIlIJ",
        "colab_type": "text"
      },
      "source": [
        "Our goal here will be to train a model to classify digits based on their pictures. Let's define the model we'll use for this task, which will consist of a convolutional layer followed by two fully-connected layers. Our model is a subclass of `nn.Module`; modules must implement a `forward()` function which defines exactly what operations get applied to the inputted data.\n",
        "\n",
        "Note that `MyModel` makes uses of the predefined modules `Conv2d` and `Linear`, which it instantiates in its constructor. Running data `x` through a module `conv1` simply consists of calling it like a function: `out = conv1(x)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8zge1JmEyAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        # 28x28x1 => 26x26x32\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
        "        self.d2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 32x1x28x28 => 32x32x26x26\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # flatten => 32 x (32*26*26)\n",
        "        x = x.flatten(start_dim = 1)\n",
        "        #x = x.view(32, -1)\n",
        "\n",
        "        # 32 x (32*26*26) => 32x128\n",
        "        x = self.d1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # logits => 32x10\n",
        "        logits = self.d2(x)\n",
        "        out = F.softmax(logits, dim=1)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81sghL-oijxb",
        "colab_type": "code",
        "outputId": "c989379c-5729-48ce-d964-4e5326a183eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import numpy as np\n",
        "a = np.array([[1,2],[3,4]])\n",
        "b = np.ones((2,2))\n",
        "\n",
        "ta = torch.tensor(a, dtype=float).to('cuda:0')\n",
        "tb = torch.ones(2,2, dtype=float).to('cuda:0')\n",
        "\n",
        "print(ta)\n",
        "print(ta @ tb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[3., 3.],\n",
            "        [7., 7.]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wbgpv4yU0MF",
        "colab_type": "text"
      },
      "source": [
        "We train our model, printing out its training accuracy along the way. We start by instantiating a model instance `model`, a loss function module `criterion` and optimizer `optimizer`, which will adjust the parameters of our model in order to minimize the loss output by `criterion`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhN99DECU6Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MyModel()\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6jDPUQiWEu4",
        "colab_type": "text"
      },
      "source": [
        "Now let's write our training loop. For each minibatch (accessed by enumerating through our data loader `trainloader`), we run our data through `model` in a forward pass, then compute the loss with `criterion`. We call `optimizer.zero_grad()` to zero out the gradients from the previous round of training, followed by `loss.backward()` to backpropagate the new round of gradients and finally `optimizer.step()` to adjust the model parameters based on these gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGoOz_zjE2EH",
        "colab_type": "code",
        "outputId": "968268b7-de5e-441e-b5c4-dce0d8effc8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    ## training step\n",
        "    for i, (images, labels) in enumerate(trainloader):\n",
        "        \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        ## forward + backprop + loss\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        ## update model params\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += (torch.argmax(logits, 1).flatten() == labels).type(torch.float).mean().item()\n",
        "    \n",
        "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
        "          %(epoch, train_running_loss / i, train_acc/i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Loss: 1.6004 | Train Accuracy: 0.86\n",
            "Epoch: 1 | Loss: 1.4922 | Train Accuracy: 0.97\n",
            "Epoch: 2 | Loss: 1.4811 | Train Accuracy: 0.98\n",
            "Epoch: 3 | Loss: 1.4766 | Train Accuracy: 0.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4bd4218cc2ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain_running_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvK4hr1OXLWu",
        "colab_type": "text"
      },
      "source": [
        "Lastly, we can run just the forward pass of our model in order to run it on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umfoz-KMW7Rs",
        "colab_type": "code",
        "outputId": "3e4eaeb0-8d4c-4c40-99f3-2ad0cb659b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_acc = 0.0\n",
        "for i, (images, labels) in enumerate(testloader, 0):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    test_acc += (torch.argmax(outputs, 1).flatten() == labels).type(torch.float).mean().item()\n",
        "    preds = torch.argmax(outputs, 1).flatten().cpu().numpy()\n",
        "        \n",
        "print('Test Accuracy: %.2f'%(test_acc/i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ4OIG8r5EfI",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyzIhe0O5ije",
        "colab_type": "text"
      },
      "source": [
        "Let's first install PyTorch Geometric (which we'll use for creating graph neural networks) and TensorboardX (which we'll use to visualize training progress):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwTG61Ibo4dG",
        "colab_type": "code",
        "outputId": "b60137da-5597-44f8-ba9a-b9d17543ef42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --verbose --no-cache-dir torch-scatter\n",
        "!pip install --verbose --no-cache-dir torch-sparse\n",
        "!pip install --verbose --no-cache-dir torch-cluster\n",
        "!pip install torch-geometric\n",
        "!pip install tensorboardX\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-9ppotubf\n",
            "Created temporary directory: /tmp/pip-req-tracker-v7em84_z\n",
            "Created requirements tracker '/tmp/pip-req-tracker-v7em84_z'\n",
            "Created temporary directory: /tmp/pip-install-ey4kfimn\n",
            "1 location(s) to search for versions of torch-scatter:\n",
            "* https://pypi.org/simple/torch-scatter/\n",
            "Getting page https://pypi.org/simple/torch-scatter/\n",
            "Found index url https://pypi.org/simple\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-scatter/ HTTP/1.1\" 200 1192\n",
            "Analyzing links from page https://pypi.org/simple/torch-scatter/\n",
            "  Found link https://files.pythonhosted.org/packages/29/96/566ac314e796d4b07209a3b88cc7a8d2e8582d55819e33f72e6c0e8d8216/torch_scatter-0.3.0.tar.gz#sha256=9e5e5a6efa4ef45f584e8611f83690d799370dd122b862646751ae112b685b50 (from https://pypi.org/simple/torch-scatter/), version: 0.3.0\n",
            "  Found link https://files.pythonhosted.org/packages/6a/b0/ecffacddf573c147c70c6e43ce05d24f007155ce3fb436959d3d2a24da46/torch_scatter-1.0.2.tar.gz#sha256=ccda794c25265b3450206b7fb0bf74f16a0b45f3f72d9547a42e44648a32faee (from https://pypi.org/simple/torch-scatter/), version: 1.0.2\n",
            "  Found link https://files.pythonhosted.org/packages/08/09/07b106f3e74246f4ecf6517013a053b6dd7486c4f889d81f39adc662431f/torch_scatter-1.0.3.tar.gz#sha256=e626993194819ba65cdf89a52fbbb7780569d9e157bc63dbef13ead6b7a33930 (from https://pypi.org/simple/torch-scatter/), version: 1.0.3\n",
            "  Found link https://files.pythonhosted.org/packages/2d/70/df2bc259d9606f00854ca43b6839f9047ec44900563435e0067584c93864/torch_scatter-1.0.4.tar.gz#sha256=ec004d687e47da9d5477407849d815629fc8b571ee87aeeebf6af8ed6f16defc (from https://pypi.org/simple/torch-scatter/), version: 1.0.4\n",
            "  Found link https://files.pythonhosted.org/packages/2f/97/c50a6aeaedc6924180c6f5810d2a7405ce11aa9b82ba4284badad549d665/torch_scatter-1.1.0.tar.gz#sha256=e534cc2ecb2f9d9b559b1513cd411737d26ea5585d1d65ff571fec55f42a49de (from https://pypi.org/simple/torch-scatter/), version: 1.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/91/5f/eb1d3ef3810cb1165859d40db4d9ee6d7f1dfef97d7e5c34010055f43d95/torch_scatter-1.1.1.tar.gz#sha256=9db7f2c0a5cddf6cfde633e33db7c2c94eaab163e9f8edb46460d6414cc97917 (from https://pypi.org/simple/torch-scatter/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/d4/83/67eeea00c2db1959e2ff95d8680dbd756977bfab254bda8658f09dc3bc11/torch_scatter-1.1.2.tar.gz#sha256=766c2476f5da5ffc25fa8e249ccf50f594031cdce3922abb23559e8e3b14337a (from https://pypi.org/simple/torch-scatter/), version: 1.1.2\n",
            "  Found link https://files.pythonhosted.org/packages/07/c0/f7ac424496f4a3bcb31aa993fba29077a6d42fc2624c66e90b58a566a98e/torch_scatter-1.2.0.tar.gz#sha256=3a0259105d07d264c740eec8e4267260a5c144cf55472abd26022fff4fd73281 (from https://pypi.org/simple/torch-scatter/), version: 1.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/24/b7/680c3b392a4b55a0ebfb480aabb0d5c188e94bb21790104175c8cd614947/torch_scatter-1.3.0.tar.gz#sha256=bf7d561b8ef12b39a99f5797c90b989a0ce2c3ee4de74dff3b170f2d8566e1d4 (from https://pypi.org/simple/torch-scatter/), version: 1.3.0\n",
            "  Found link https://files.pythonhosted.org/packages/35/d4/750403a8aa32cdb3d2d05849c6a10e4e0604de5e0cc94b81a0d0d69a75f3/torch_scatter-1.3.1.tar.gz#sha256=54cbad248350165ddc921ded3fe7a69be5d30c6536273a1a3282e375289f86ec (from https://pypi.org/simple/torch-scatter/), version: 1.3.1\n",
            "  Found link https://files.pythonhosted.org/packages/30/d9/1d5fd4d183dabd9e0a1f7008ecf83318432359f4cc27480e3f2212f44d9c/torch_scatter-1.3.2.tar.gz#sha256=890e8f9da2d57431912182960b71bf6c56397de42c2464907a6e9c583164bf06 (from https://pypi.org/simple/torch-scatter/), version: 1.3.2\n",
            "Given no hashes to check 11 links for project 'torch-scatter': discarding no candidates\n",
            "Using version 1.3.2 (newest of versions: 0.3.0, 1.0.2, 1.0.3, 1.0.4, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.3.0, 1.3.1, 1.3.2)\n",
            "Collecting torch-scatter\n",
            "  Created temporary directory: /tmp/pip-unpack-0fgzu2lu\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/30/d9/1d5fd4d183dabd9e0a1f7008ecf83318432359f4cc27480e3f2212f44d9c/torch_scatter-1.3.2.tar.gz HTTP/1.1\" 200 13563\n",
            "  Downloading https://files.pythonhosted.org/packages/30/d9/1d5fd4d183dabd9e0a1f7008ecf83318432359f4cc27480e3f2212f44d9c/torch_scatter-1.3.2.tar.gz\n",
            "  Added torch-scatter from https://files.pythonhosted.org/packages/30/d9/1d5fd4d183dabd9e0a1f7008ecf83318432359f4cc27480e3f2212f44d9c/torch_scatter-1.3.2.tar.gz#sha256=890e8f9da2d57431912182960b71bf6c56397de42c2464907a6e9c583164bf06 to build tracker '/tmp/pip-req-tracker-v7em84_z'\n",
            "    Running setup.py (path:/tmp/pip-install-ey4kfimn/torch-scatter/setup.py) egg_info for package torch-scatter\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-ey4kfimn/torch-scatter/pip-egg-info/torch_scatter.egg-info\n",
            "    writing /tmp/pip-install-ey4kfimn/torch-scatter/pip-egg-info/torch_scatter.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-ey4kfimn/torch-scatter/pip-egg-info/torch_scatter.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-install-ey4kfimn/torch-scatter/pip-egg-info/torch_scatter.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-ey4kfimn/torch-scatter/pip-egg-info/torch_scatter.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-ey4kfimn/torch-scatter/pip-egg-info/torch_scatter.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    writing manifest file '/tmp/pip-install-ey4kfimn/torch-scatter/pip-egg-info/torch_scatter.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-ey4kfimn/torch-scatter has version 1.3.2, which satisfies requirement torch-scatter from https://files.pythonhosted.org/packages/30/d9/1d5fd4d183dabd9e0a1f7008ecf83318432359f4cc27480e3f2212f44d9c/torch_scatter-1.3.2.tar.gz#sha256=890e8f9da2d57431912182960b71bf6c56397de42c2464907a6e9c583164bf06\n",
            "  Removed torch-scatter from https://files.pythonhosted.org/packages/30/d9/1d5fd4d183dabd9e0a1f7008ecf83318432359f4cc27480e3f2212f44d9c/torch_scatter-1.3.2.tar.gz#sha256=890e8f9da2d57431912182960b71bf6c56397de42c2464907a6e9c583164bf06 from build tracker '/tmp/pip-req-tracker-v7em84_z'\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Created temporary directory: /tmp/pip-wheel-jqk5c799\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-jqk5c799\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-ey4kfimn/torch-scatter/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-ey4kfimn/torch-scatter/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-jqk5c799 --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.6\n",
            "  creating build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/std.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/max.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/div.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/add.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/__init__.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/min.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/mean.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/mul.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/sub.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  creating build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_forward.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_multi_gpu.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_max_min.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_broadcasting.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_backward.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_std.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.6/test\n",
            "  creating build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  copying torch_scatter/utils/gen.py -> build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  copying torch_scatter/utils/__init__.py -> build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  copying torch_scatter/utils/ext.py -> build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  running build_ext\n",
            "  building 'torch_scatter.scatter_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.6\n",
            "  creating build/temp.linux-x86_64-3.6/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/scatter.cpp -o build/temp.linux-x86_64-3.6/cpu/scatter.o -Wno-unused-variable -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/scatter.o -o build/lib.linux-x86_64-3.6/torch_scatter/scatter_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_scatter.scatter_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.6/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/scatter.cpp -o build/temp.linux-x86_64-3.6/cuda/scatter.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/scatter_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/scatter_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/scatter.o build/temp.linux-x86_64-3.6/cuda/scatter_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_scatter/scatter_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/scatter_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/std.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/max.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/div.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/add.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/__init__.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/min.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/mean.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/utils/gen.py -> build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/utils/__init__.py -> build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/utils/ext.py -> build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/mul.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/sub.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/scatter_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  creating build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_forward.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_multi_gpu.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_max_min.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_broadcasting.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_backward.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_std.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/__init__.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/utils.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_scatter.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
            "  writing top-level names to torch_scatter.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
            "  Copying torch_scatter.egg-info to build/bdist.linux-x86_64/wheel/torch_scatter-1.3.2-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter-1.3.2.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-jqk5c799/torch_scatter-1.3.2-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'test/__init__.py'\n",
            "  adding 'test/test_backward.py'\n",
            "  adding 'test/test_broadcasting.py'\n",
            "  adding 'test/test_forward.py'\n",
            "  adding 'test/test_max_min.py'\n",
            "  adding 'test/test_multi_gpu.py'\n",
            "  adding 'test/test_std.py'\n",
            "  adding 'test/utils.py'\n",
            "  adding 'torch_scatter/__init__.py'\n",
            "  adding 'torch_scatter/add.py'\n",
            "  adding 'torch_scatter/div.py'\n",
            "  adding 'torch_scatter/max.py'\n",
            "  adding 'torch_scatter/mean.py'\n",
            "  adding 'torch_scatter/min.py'\n",
            "  adding 'torch_scatter/mul.py'\n",
            "  adding 'torch_scatter/scatter_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_scatter/scatter_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_scatter/std.py'\n",
            "  adding 'torch_scatter/sub.py'\n",
            "  adding 'torch_scatter/utils/__init__.py'\n",
            "  adding 'torch_scatter/utils/ext.py'\n",
            "  adding 'torch_scatter/utils/gen.py'\n",
            "  adding 'torch_scatter-1.3.2.dist-info/LICENSE'\n",
            "  adding 'torch_scatter-1.3.2.dist-info/METADATA'\n",
            "  adding 'torch_scatter-1.3.2.dist-info/WHEEL'\n",
            "  adding 'torch_scatter-1.3.2.dist-info/top_level.txt'\n",
            "  adding 'torch_scatter-1.3.2.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-1.3.2-cp36-cp36m-linux_x86_64.whl size=2858592 sha256=ce69a0a5f56ccb8b380b7cfb70b7a32c4720240a77a79481b6b1d02afd8d77d4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9ppotubf/wheels/40/30/07/5400c1a1ec05c5d0d6459fb2179d0e12c7c2f6d3d47987bf10\n",
            "  Removing source in /tmp/pip-install-ey4kfimn/torch-scatter\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "\n",
            "Successfully installed torch-scatter-1.3.2\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-v7em84_z'\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-oql18q6g\n",
            "Created temporary directory: /tmp/pip-req-tracker-y50vkgkv\n",
            "Created requirements tracker '/tmp/pip-req-tracker-y50vkgkv'\n",
            "Created temporary directory: /tmp/pip-install-2ewgjfjg\n",
            "1 location(s) to search for versions of torch-sparse:\n",
            "* https://pypi.org/simple/torch-sparse/\n",
            "Getting page https://pypi.org/simple/torch-sparse/\n",
            "Found index url https://pypi.org/simple\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-sparse/ HTTP/1.1\" 200 1096\n",
            "Analyzing links from page https://pypi.org/simple/torch-sparse/\n",
            "  Found link https://files.pythonhosted.org/packages/21/a6/af5865f7bc2dc45ea789ebb35bdf5d84c05e140d7d2ec7e5823d24db176f/torch_sparse-0.1.0.tar.gz#sha256=d774c4b05a96bf09e3c3becd2f48c65ed66b03195a2cfc4992ef57c9a8c6b399 (from https://pypi.org/simple/torch-sparse/), version: 0.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/02/4f/89bcb156022a3960c4db852915c64ea78b4e993e0f8d7a83e60e6819fc11/torch_sparse-0.2.0.tar.gz#sha256=578fdc3522b06c948d43fbc360d0dcde8a89d9a2496ac468592bf3493baedd33 (from https://pypi.org/simple/torch-sparse/), version: 0.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/8f/41/98db80cc9d9345c76445393661ce4dd3e08fc46fb17028e7706612063e4d/torch_sparse-0.2.1.tar.gz#sha256=01346234f0e76103304f8aa1099f22c0904d2fff8b36c5ec0230335149f526bc (from https://pypi.org/simple/torch-sparse/), version: 0.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/73/5b/5b7b6c66148afaa5e2ed8a3e18e109361957d28e67032d92cb282d173f32/torch_sparse-0.2.2.tar.gz#sha256=11e87c0214a4491168f15726ddda6c771b5f34be728f3edbb4add203e46d924d (from https://pypi.org/simple/torch-sparse/), version: 0.2.2\n",
            "  Found link https://files.pythonhosted.org/packages/43/2a/bb2ead5b33c6932937c6c74199ebecd72bd4b3ab224842a50366e5b2af4a/torch_sparse-0.2.3.tar.gz#sha256=47b3f85b0c243d0c98798db722b0f066830f6b8ff9d298a6e2aed0662598e356 (from https://pypi.org/simple/torch-sparse/), version: 0.2.3\n",
            "  Found link https://files.pythonhosted.org/packages/73/72/e374662f6f47d9ac0e082a6d5c18d14e15c52863e89c6bc6957a0d2ed026/torch_sparse-0.2.4.tar.gz#sha256=5cae8b40a5d11b8917e0f4b95034b5842b052f42a089ce59f8c02f2cff00ca55 (from https://pypi.org/simple/torch-sparse/), version: 0.2.4\n",
            "  Found link https://files.pythonhosted.org/packages/b0/0a/2ff678e0d04e524dd2cf990a6202ced8c0ffe3fe6b08e02f25cc9fd27da0/torch_sparse-0.4.0.tar.gz#sha256=bf217539b4f714a1d6fac4d39ace3ad8033871717f44f8f365a2746056b9d805 (from https://pypi.org/simple/torch-sparse/), version: 0.4.0\n",
            "  Found link https://files.pythonhosted.org/packages/c7/3e/aa5449787910283d846a7c739899ccf8c53c914f8a7aee7bc500a32dc091/torch_sparse-0.4.1.tar.gz#sha256=4831fe4b78b86d4dff948d50fec042ef99b98e850495b400189456380ec397d4 (from https://pypi.org/simple/torch-sparse/), version: 0.4.1\n",
            "  Found link https://files.pythonhosted.org/packages/7d/c5/1f73917168aa9816f41e0696f266fa07d0ebfe8d25c3e63a0f08440534b9/torch_sparse-0.4.2.tar.gz#sha256=a652feb1b945995fb863dcbfdaa01de9096d5ed7230380ebf6d262e649eb4123 (from https://pypi.org/simple/torch-sparse/), version: 0.4.2\n",
            "  Found link https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f (from https://pypi.org/simple/torch-sparse/), version: 0.4.3\n",
            "Given no hashes to check 10 links for project 'torch-sparse': discarding no candidates\n",
            "Using version 0.4.3 (newest of versions: 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.4.0, 0.4.1, 0.4.2, 0.4.3)\n",
            "Collecting torch-sparse\n",
            "  Created temporary directory: /tmp/pip-unpack-diu7m09t\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz HTTP/1.1\" 200 11018\n",
            "  Downloading https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz\n",
            "  Added torch-sparse from https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f to build tracker '/tmp/pip-req-tracker-y50vkgkv'\n",
            "    Running setup.py (path:/tmp/pip-install-2ewgjfjg/torch-sparse/setup.py) egg_info for package torch-sparse\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-2ewgjfjg/torch-sparse/pip-egg-info/torch_sparse.egg-info\n",
            "    writing /tmp/pip-install-2ewgjfjg/torch-sparse/pip-egg-info/torch_sparse.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-2ewgjfjg/torch-sparse/pip-egg-info/torch_sparse.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-install-2ewgjfjg/torch-sparse/pip-egg-info/torch_sparse.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-install-2ewgjfjg/torch-sparse/pip-egg-info/torch_sparse.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-2ewgjfjg/torch-sparse/pip-egg-info/torch_sparse.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-2ewgjfjg/torch-sparse/pip-egg-info/torch_sparse.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    writing manifest file '/tmp/pip-install-2ewgjfjg/torch-sparse/pip-egg-info/torch_sparse.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-2ewgjfjg/torch-sparse has version 0.4.3, which satisfies requirement torch-sparse from https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f\n",
            "  Removed torch-sparse from https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f from build tracker '/tmp/pip-req-tracker-y50vkgkv'\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse) (1.16.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Created temporary directory: /tmp/pip-wheel-do88t0g3\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-do88t0g3\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-2ewgjfjg/torch-sparse/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-2ewgjfjg/torch-sparse/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-do88t0g3 --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.6\n",
            "  creating build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/convert.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/transpose.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/__init__.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/spmm.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/eye.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  creating build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_spspmm.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_spspmm_spmm.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_spmm.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_transpose.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_eye.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_coalesce.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_convert.py -> build/lib.linux-x86_64-3.6/test\n",
            "  creating build/lib.linux-x86_64-3.6/torch_sparse/utils\n",
            "  copying torch_sparse/utils/unique.py -> build/lib.linux-x86_64-3.6/torch_sparse/utils\n",
            "  copying torch_sparse/utils/__init__.py -> build/lib.linux-x86_64-3.6/torch_sparse/utils\n",
            "  running build_ext\n",
            "  building 'torch_sparse.spspmm_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.6\n",
            "  creating build/temp.linux-x86_64-3.6/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/spspmm.cpp -o build/temp.linux-x86_64-3.6/cpu/spspmm.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=spspmm_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/spspmm.o -o build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_sparse.spspmm_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.6/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/spspmm.cpp -o build/temp.linux-x86_64-3.6/cuda/spspmm.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=spspmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/spspmm_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/spspmm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=spspmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/spspmm.o build/temp.linux-x86_64-3.6/cuda/spspmm_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cuda.cpython-36m-x86_64-linux-gnu.so -lcusparse -l cusparse\n",
            "  building 'torch_sparse.unique_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/unique.cpp -o build/temp.linux-x86_64-3.6/cuda/unique.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=unique_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/unique_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/unique_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=unique_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/unique.o build/temp.linux-x86_64-3.6/cuda/unique_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_sparse/unique_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/coalesce.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/convert.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/transpose.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spspmm.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/unique_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/__init__.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spmm.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/utils/unique.py -> build/bdist.linux-x86_64/wheel/torch_sparse/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/utils/__init__.py -> build/bdist.linux-x86_64/wheel/torch_sparse/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/eye.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  creating build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_spspmm.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_spspmm_spmm.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_spmm.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_transpose.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_eye.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/__init__.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_coalesce.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/utils.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_convert.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_sparse.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
            "  writing requirements to torch_sparse.egg-info/requires.txt\n",
            "  writing top-level names to torch_sparse.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
            "  Copying torch_sparse.egg-info to build/bdist.linux-x86_64/wheel/torch_sparse-0.4.3-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse-0.4.3.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-do88t0g3/torch_sparse-0.4.3-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'test/__init__.py'\n",
            "  adding 'test/test_coalesce.py'\n",
            "  adding 'test/test_convert.py'\n",
            "  adding 'test/test_eye.py'\n",
            "  adding 'test/test_spmm.py'\n",
            "  adding 'test/test_spspmm.py'\n",
            "  adding 'test/test_spspmm_spmm.py'\n",
            "  adding 'test/test_transpose.py'\n",
            "  adding 'test/utils.py'\n",
            "  adding 'torch_sparse/__init__.py'\n",
            "  adding 'torch_sparse/coalesce.py'\n",
            "  adding 'torch_sparse/convert.py'\n",
            "  adding 'torch_sparse/eye.py'\n",
            "  adding 'torch_sparse/spmm.py'\n",
            "  adding 'torch_sparse/spspmm.py'\n",
            "  adding 'torch_sparse/spspmm_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_sparse/spspmm_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_sparse/transpose.py'\n",
            "  adding 'torch_sparse/unique_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_sparse/utils/__init__.py'\n",
            "  adding 'torch_sparse/utils/unique.py'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/LICENSE'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/METADATA'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/WHEEL'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/top_level.txt'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.4.3-cp36-cp36m-linux_x86_64.whl size=3966544 sha256=a7f145fe0e91b0f92627505fa0866e61a2ae7c1e3ea94cc8a863ab5e3bed0636\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oql18q6g/wheels/02/66/2b/befece01c2516f9fb3e7b4d150bb2b871221c73657c9cd7735\n",
            "  Removing source in /tmp/pip-install-2ewgjfjg/torch-sparse\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "\n",
            "Successfully installed torch-sparse-0.4.3\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-y50vkgkv'\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-oi77n4lx\n",
            "Created temporary directory: /tmp/pip-req-tracker-p64wqxfc\n",
            "Created requirements tracker '/tmp/pip-req-tracker-p64wqxfc'\n",
            "Created temporary directory: /tmp/pip-install-9oum66ig\n",
            "1 location(s) to search for versions of torch-cluster:\n",
            "* https://pypi.org/simple/torch-cluster/\n",
            "Getting page https://pypi.org/simple/torch-cluster/\n",
            "Found index url https://pypi.org/simple\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-cluster/ HTTP/1.1\" 200 2174\n",
            "Analyzing links from page https://pypi.org/simple/torch-cluster/\n",
            "  Found link https://files.pythonhosted.org/packages/58/77/1ddc3390129653d1e0e1e0c8063d47a2f40abc888d95b4a2fba774e215df/torch_cluster-0.1.1.tar.gz#sha256=f4f64eabc4c380bff9863d3ce9b93b0a65c7ea6f797f9ee053dc74d7d92ea928 (from https://pypi.org/simple/torch-cluster/), version: 0.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/ac/92/c583aabacb052afed67db146662c23625ad861a74140e338996816a879f4/torch_cluster-0.2.3.tar.gz#sha256=43d9840078f962abfced55043d8320f80c7f91aa7f54398b9ad631ee577bbfb1 (from https://pypi.org/simple/torch-cluster/), version: 0.2.3\n",
            "  Found link https://files.pythonhosted.org/packages/6e/9b/493def262b256290ad6913c9f36b774af6f52d9d46d3fee31b77b3803eb0/torch_cluster-0.2.4.tar.gz#sha256=f421986d71a644b72c69551f09df31eb8657203d59d639aac33192192ed675b5 (from https://pypi.org/simple/torch-cluster/), version: 0.2.4\n",
            "  Found link https://files.pythonhosted.org/packages/8a/2c/ddf6e6fc9c4af6c37a20996100cf6a6427accd7939470bc99071d3487753/torch_cluster-1.0.1.tar.gz#sha256=04cf3ad486eff6cc6069e3d1c18a2acd7662169f36d02a13f3a7adaabfc06b91 (from https://pypi.org/simple/torch-cluster/), version: 1.0.1\n",
            "  Found link https://files.pythonhosted.org/packages/87/9d/e488a5186684632e3e0f14eaec125936cf25a3a24552afd26e7bb426d2ee/torch_cluster-1.0.3.tar.gz#sha256=795264f9e9f36eb44aeb28716d68ea93cd6dc7f75c8e05e0d16eb0597ffcd1a6 (from https://pypi.org/simple/torch-cluster/), version: 1.0.3\n",
            "  Found link https://files.pythonhosted.org/packages/7b/95/bca3179ce501792bf268d37f18cc82577c289fa093bfdcfc26e375019da5/torch_cluster-1.1.1.tar.gz#sha256=e919f64153fd97efe958a509a0a558a31bf5f2dbe2deeff09d300e33d3994b14 (from https://pypi.org/simple/torch-cluster/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/36/b0/25ca8b811059e001f1e3285ac3036b6969fb21350e411c6881ba2b9be3c3/torch_cluster-1.1.2.tar.gz#sha256=082c4e71079cd1bed89da4178b3391361fa6aac5ae2edb783c08fed3da5b93c4 (from https://pypi.org/simple/torch-cluster/), version: 1.1.2\n",
            "  Found link https://files.pythonhosted.org/packages/e2/4f/5205f832d3eef871fe71564aa9fb8504a65be5e95be09800e125e224e634/torch_cluster-1.1.3.tar.gz#sha256=d5c80159f91e329bcc95b316a29ecf466257598680b3b5fb2ea137a585037c78 (from https://pypi.org/simple/torch-cluster/), version: 1.1.3\n",
            "  Found link https://files.pythonhosted.org/packages/d0/e1/495ecc73f1e5534ecbedf1a301557d6c9fc93417467e5107fd9ac54fcbfa/torch_cluster-1.1.4.tar.gz#sha256=a298694afe91f146be3921b8c9da06051958b7598c6e69a9af5833a1af56e7f3 (from https://pypi.org/simple/torch-cluster/), version: 1.1.4\n",
            "  Found link https://files.pythonhosted.org/packages/a6/b3/de9c051d1df504d78542d178231f2ae7d08a411c9ca59219028742886947/torch_cluster-1.1.5.tar.gz#sha256=b67d6c89b71e4146dcfa078cc6a201a1647d888441a9f278b30770f91c7978a1 (from https://pypi.org/simple/torch-cluster/), version: 1.1.5\n",
            "  Found link https://files.pythonhosted.org/packages/96/de/9506fa869cf52edc58c2517b41c0ec1c7678c05b95aff000a509e4238765/torch_cluster-1.2.1.tar.gz#sha256=371b438113bcb7cab1b6931740e9194972f0f7349e1d033437a4196d7d693130 (from https://pypi.org/simple/torch-cluster/), version: 1.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/33/b7/05b9ce9afc76f5709efe04d6344fbed09ea217f916f94e63f2fe9659eb62/torch_cluster-1.2.2.tar.gz#sha256=a1e39e16a7ade806a852117fe16fe2b505fd4bc43bc4207f48fecb0f6b2e1f64 (from https://pypi.org/simple/torch-cluster/), version: 1.2.2\n",
            "  Found link https://files.pythonhosted.org/packages/67/19/a0b1e3a7633ced39d9977ce0b98a1b3e343f0772f4090b0a2d421ac5b56d/torch_cluster-1.2.3.tar.gz#sha256=f8a6b5f47bf6a2a396301d0f4ec0733a650f7a5ae84b08b8625408b8979747ea (from https://pypi.org/simple/torch-cluster/), version: 1.2.3\n",
            "  Found link https://files.pythonhosted.org/packages/32/c8/9b3af10be647326dd807bb2fe7ced8ae4c3fd74178dba884621749afc4d7/torch_cluster-1.2.4.tar.gz#sha256=4e5f8c15b28329b269adecadd64917cb5373c6438a5fdf463f633bd4e73c4ae6 (from https://pypi.org/simple/torch-cluster/), version: 1.2.4\n",
            "  Found link https://files.pythonhosted.org/packages/93/f9/89319a7344e5bcda090fb3996c4271b1fda238ad90401a315c9af1ce4137/torch_cluster-1.3.0.tar.gz#sha256=7b0e1b7061bf8c2754d63a66159f47757ce28b072bc37921fbcc59974eb2d342 (from https://pypi.org/simple/torch-cluster/), version: 1.3.0\n",
            "  Found link https://files.pythonhosted.org/packages/6b/3b/a34740494a1b25cb2ef4ed09e5d5ef6bc75be884f6b25bd93a7acdf03134/torch_cluster-1.4.0.tar.gz#sha256=c256d61f20193b104a2f4c610b4ad95fa3cbaeb72b2ae9bf3d254cb3d573e945 (from https://pypi.org/simple/torch-cluster/), version: 1.4.0\n",
            "  Found link https://files.pythonhosted.org/packages/2f/0c/77453228c248e8071d185940ecb3dd9eca3cac180767bde75b2bc05c0c65/torch_cluster-1.4.1.tar.gz#sha256=e7a900d54cb2dc241c84b1da382f358399880c61290f7be72babf98500496494 (from https://pypi.org/simple/torch-cluster/), version: 1.4.1\n",
            "  Found link https://files.pythonhosted.org/packages/33/38/60ad2fcb735123429b3e0b165a19c80c6273d679b01d6550782abcb314e2/torch_cluster-1.4.2.tar.gz#sha256=ed437ec01f431d0f36398cc321524aac27870cc09e7a5a869726af9c15ac354a (from https://pypi.org/simple/torch-cluster/), version: 1.4.2\n",
            "  Found link https://files.pythonhosted.org/packages/7e/30/b315f136648801433ce6b2724fe3bfaae3c0f8a13282aa58d38ad2a8a3db/torch_cluster-1.4.3a1.tar.gz#sha256=680e47ee41a0cec223c179ce3ea2174de48ac6a277eced453ccadf4bdd2f51c9 (from https://pypi.org/simple/torch-cluster/), version: 1.4.3a1\n",
            "  Found link https://files.pythonhosted.org/packages/49/0d/f7151fb6aad5c9b0e032e46c0678e0404870de4add35b0723fc2a5c4af35/torch_cluster-1.4.3.tar.gz#sha256=340eaf9e31a7a0618f2c3d61c480e1d74466c930827f10fee86d11d8c5b85cba (from https://pypi.org/simple/torch-cluster/), version: 1.4.3\n",
            "  Found link https://files.pythonhosted.org/packages/bd/5f/01c5799cd1f81f9956f03a0e1d9a861e020a598dd411d9bd3c3c1dd5b8a4/torch_cluster-1.4.4.tar.gz#sha256=7907f3f270116cb299bdd4f88de497a85b3b34cf127910ffe0a6131e16620123 (from https://pypi.org/simple/torch-cluster/), version: 1.4.4\n",
            "  Found link https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257 (from https://pypi.org/simple/torch-cluster/), version: 1.4.5\n",
            "Given no hashes to check 21 links for project 'torch-cluster': discarding no candidates\n",
            "Using version 1.4.5 (newest of versions: 0.1.1, 0.2.3, 0.2.4, 1.0.1, 1.0.3, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.3.0, 1.4.0, 1.4.1, 1.4.2, 1.4.3, 1.4.4, 1.4.5)\n",
            "Collecting torch-cluster\n",
            "  Created temporary directory: /tmp/pip-unpack-wqm0uqlu\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz HTTP/1.1\" 200 18790\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz\n",
            "  Added torch-cluster from https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257 to build tracker '/tmp/pip-req-tracker-p64wqxfc'\n",
            "    Running setup.py (path:/tmp/pip-install-9oum66ig/torch-cluster/setup.py) egg_info for package torch-cluster\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-9oum66ig/torch-cluster/pip-egg-info/torch_cluster.egg-info\n",
            "    writing /tmp/pip-install-9oum66ig/torch-cluster/pip-egg-info/torch_cluster.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-9oum66ig/torch-cluster/pip-egg-info/torch_cluster.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-install-9oum66ig/torch-cluster/pip-egg-info/torch_cluster.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-install-9oum66ig/torch-cluster/pip-egg-info/torch_cluster.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-9oum66ig/torch-cluster/pip-egg-info/torch_cluster.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-9oum66ig/torch-cluster/pip-egg-info/torch_cluster.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    writing manifest file '/tmp/pip-install-9oum66ig/torch-cluster/pip-egg-info/torch_cluster.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-9oum66ig/torch-cluster has version 1.4.5, which satisfies requirement torch-cluster from https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257\n",
            "  Removed torch-cluster from https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257 from build tracker '/tmp/pip-req-tracker-p64wqxfc'\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster) (1.16.5)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Created temporary directory: /tmp/pip-wheel-rxl8_qb1\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-rxl8_qb1\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-9oum66ig/torch-cluster/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-9oum66ig/torch-cluster/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-rxl8_qb1 --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.6\n",
            "  creating build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/fps.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/sampler.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/knn.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/nearest.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/radius.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/graclus.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/__init__.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/rw.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/grid.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  creating build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_knn.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_rw.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_fps.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_nearest.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_sampler.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_radius.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_grid.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_graclus.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.6/test\n",
            "  running build_ext\n",
            "  building 'torch_cluster.graclus_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.6\n",
            "  creating build/temp.linux-x86_64-3.6/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/graclus.cpp -o build/temp.linux-x86_64-3.6/cpu/graclus.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=graclus_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/graclus.o -o build/lib.linux-x86_64-3.6/torch_cluster/graclus_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.grid_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/grid.cpp -o build/temp.linux-x86_64-3.6/cpu/grid.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=grid_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/grid.o -o build/lib.linux-x86_64-3.6/torch_cluster/grid_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.fps_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/fps.cpp -o build/temp.linux-x86_64-3.6/cpu/fps.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fps_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/fps.o -o build/lib.linux-x86_64-3.6/torch_cluster/fps_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.rw_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/rw.cpp -o build/temp.linux-x86_64-3.6/cpu/rw.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=rw_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/rw.o -o build/lib.linux-x86_64-3.6/torch_cluster/rw_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.sampler_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/sampler.cpp -o build/temp.linux-x86_64-3.6/cpu/sampler.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=sampler_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/sampler.o -o build/lib.linux-x86_64-3.6/torch_cluster/sampler_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.graclus_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.6/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/graclus.cpp -o build/temp.linux-x86_64-3.6/cuda/graclus.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=graclus_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/graclus_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/graclus_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=graclus_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/graclus.o build/temp.linux-x86_64-3.6/cuda/graclus_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/graclus_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.grid_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/grid.cpp -o build/temp.linux-x86_64-3.6/cuda/grid.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=grid_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/grid_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/grid_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=grid_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/grid.o build/temp.linux-x86_64-3.6/cuda/grid_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/grid_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.fps_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/fps.cpp -o build/temp.linux-x86_64-3.6/cuda/fps.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fps_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/fps_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/fps_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fps_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/fps.o build/temp.linux-x86_64-3.6/cuda/fps_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/fps_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.nearest_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/nearest.cpp -o build/temp.linux-x86_64-3.6/cuda/nearest.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nearest_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/nearest_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/nearest_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nearest_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/nearest.o build/temp.linux-x86_64-3.6/cuda/nearest_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/nearest_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.knn_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/knn.cpp -o build/temp.linux-x86_64-3.6/cuda/knn.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=knn_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/knn_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/knn_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=knn_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/knn.o build/temp.linux-x86_64-3.6/cuda/knn_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/knn_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.radius_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/radius.cpp -o build/temp.linux-x86_64-3.6/cuda/radius.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=radius_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/radius_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/radius_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=radius_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/radius.o build/temp.linux-x86_64-3.6/cuda/radius_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/radius_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.rw_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/rw.cpp -o build/temp.linux-x86_64-3.6/cuda/rw.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/rw_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/rw_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/rw.o build/temp.linux-x86_64-3.6/cuda/rw_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/rw_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/fps.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/grid_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/fps_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/sampler.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/knn.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/graclus_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/nearest.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/radius.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/graclus.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/rw_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/fps_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/__init__.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/radius_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/rw_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/nearest_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/grid_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/graclus_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/rw.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/knn_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/sampler_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/grid.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  creating build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_knn.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_rw.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_fps.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_nearest.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_sampler.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_radius.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/__init__.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_grid.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_graclus.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/utils.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_cluster.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_cluster.egg-info/dependency_links.txt\n",
            "  writing requirements to torch_cluster.egg-info/requires.txt\n",
            "  writing top-level names to torch_cluster.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_cluster.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'torch_cluster.egg-info/SOURCES.txt'\n",
            "  Copying torch_cluster.egg-info to build/bdist.linux-x86_64/wheel/torch_cluster-1.4.5-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_cluster-1.4.5.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-rxl8_qb1/torch_cluster-1.4.5-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'test/__init__.py'\n",
            "  adding 'test/test_fps.py'\n",
            "  adding 'test/test_graclus.py'\n",
            "  adding 'test/test_grid.py'\n",
            "  adding 'test/test_knn.py'\n",
            "  adding 'test/test_nearest.py'\n",
            "  adding 'test/test_radius.py'\n",
            "  adding 'test/test_rw.py'\n",
            "  adding 'test/test_sampler.py'\n",
            "  adding 'test/utils.py'\n",
            "  adding 'torch_cluster/__init__.py'\n",
            "  adding 'torch_cluster/fps.py'\n",
            "  adding 'torch_cluster/fps_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/fps_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/graclus.py'\n",
            "  adding 'torch_cluster/graclus_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/graclus_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/grid.py'\n",
            "  adding 'torch_cluster/grid_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/grid_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/knn.py'\n",
            "  adding 'torch_cluster/knn_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/nearest.py'\n",
            "  adding 'torch_cluster/nearest_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/radius.py'\n",
            "  adding 'torch_cluster/radius_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/rw.py'\n",
            "  adding 'torch_cluster/rw_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/rw_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/sampler.py'\n",
            "  adding 'torch_cluster/sampler_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/LICENSE'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/METADATA'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/WHEEL'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/top_level.txt'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.4.5-cp36-cp36m-linux_x86_64.whl size=16218663 sha256=f951baca0d67efc0b5f96478a4418d531f12100f03097358f273617b24ea0c6e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oi77n4lx/wheels/0a/26/7e/a6d6a80eae5ca39b92bc77773f36cf433d5085de18014382b1\n",
            "  Removing source in /tmp/pip-install-9oum66ig/torch-cluster\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "\n",
            "Successfully installed torch-cluster-1.4.5\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-p64wqxfc'\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/50/0a802f0bfa68058bf025d219ec6fbe806a5b891bba6702e28be7b83679fb/torch_geometric-1.3.2.tar.gz (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.16.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.21.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/15/434d1d96f9a41fea56cb3290718123d651c56c4b7e53f0249acaf1bf34b6/plyfile-0.7.1.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.24.2)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.8.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2019.9.11)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.2)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.12.0)\n",
            "Building wheels for collected packages: torch-geometric, plyfile\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.3.2-cp36-none-any.whl size=203339 sha256=cad0d31359fa936fdc3fe5ada88028638bfcb0a1e117525edbce960d1ef51da5\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/75/0a/56a0fd58efac6d990782523e20e61c9307fc42c31564d40348\n",
            "  Building wheel for plyfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plyfile: filename=plyfile-0.7.1-cp36-none-any.whl size=32827 sha256=a1e653299b14ad59338a42e7a5169bb53a179fb144acfbc0ac63d1d64c906653\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/0d/bf/6d603d81b98604d2ecfd5e99d4ab7c9af664fd5285ab82bbb0\n",
            "Successfully built torch-geometric plyfile\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.1 rdflib-4.2.2 torch-geometric-1.3.2\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5c/e918d9f190baab8d55bad52840d8091dd5114cc99f03eaa6d72d404503cc/tensorboardX-1.9-py2.py3-none-any.whl (190kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (41.4.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.9\n",
            "--2019-10-24 02:34:31--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 35.170.135.225, 35.170.171.200, 34.202.88.140, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|35.170.135.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  59.9MB/s    in 0.2s    \n",
            "\n",
            "2019-10-24 02:34:32 (59.9 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z550TutV5vhQ",
        "colab_type": "text"
      },
      "source": [
        "Import everything we need:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlFlxfL5dgn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCgqxSiq6I4B",
        "colab_type": "text"
      },
      "source": [
        "# Defining the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nc20DEc6PO5",
        "colab_type": "text"
      },
      "source": [
        "The `GNNStack` is our general framework for a GNN which can handle different types of convolutional layers, and both node and graph classification. The `build_conv_model` method determines which type of convolutional layer to use for the given task -- here we choose to use a graph convolutional network for node classification, and a graph isomorphism network for graph classification. Note that PyTorch Geometric provides out-of-the-box modules for these layers, which we use here. The model consists of 3 layers of convolution, followed by mean pooling in the case of graph classification, followed by two fully-connected layers. Since our goal here is classification, we use a negative log-likelihood loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymy1pgN5oNQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GNNStack(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, task='node'):\n",
        "        super(GNNStack, self).__init__()\n",
        "        self.task = task\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
        "        for l in range(2):\n",
        "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25), \n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "        if not (self.task == 'node' or self.task == 'graph'):\n",
        "            raise RuntimeError('Unknown task.')\n",
        "\n",
        "        self.dropout = 0.25\n",
        "        self.num_layers = 3\n",
        "\n",
        "    def build_conv_model(self, input_dim, hidden_dim):\n",
        "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
        "        if self.task == 'node':\n",
        "            return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
        "        else:\n",
        "            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
        "                                  nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        if data.num_node_features == 0:\n",
        "          x = torch.ones(data.num_nodes, 1)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            emb = x\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        if self.task == 'graph':\n",
        "            x = pyg_nn.global_mean_pool(x, batch)\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        return emb, F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l8hy4NSvu7J",
        "colab_type": "text"
      },
      "source": [
        "Here pyg_nn.GCNConv and pyg_nn.GINConv are instances of MessagePassing. They define a single layer of graph convolution, which can be decomposed into:\n",
        "* Message computation\n",
        "* Aggregation\n",
        "* Update\n",
        "* Pooling\n",
        "\n",
        "Here we give an example of how to subclass the pytorch geometric MessagePassing class to derive a new model (rather than using existing GCNConv and GINConv).\n",
        "\n",
        "We make use of `MessagePassing`'s key building blocks:\n",
        "- `aggr='add'`: The aggregation method to use (\"add\", \"mean\" or \"max\").\n",
        "- `propagate()`: The initial call to start propagating messages. Takes in the edge indices and any other data to pass along (e.g. to update node embeddings).\n",
        "- `message()`: Constructs messages to node i. Takes any argument which was initially passed to propagate().\n",
        "- `update()`: Updates node embeddings. Takes in the output of aggregation as first argument and any argument which was initially passed to propagate().\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_0yhAPgvttr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomConv(pyg_nn.MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CustomConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
        "        self.lin = nn.Linear(in_channels, out_channels)\n",
        "        self.lin_self = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "\n",
        "        # Add self-loops to the adjacency matrix.\n",
        "        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n",
        "\n",
        "        # Transform node feature matrix.\n",
        "        self_x = self.lin_self(x)\n",
        "        #x = self.lin(x)\n",
        "\n",
        "        return self_x + self.propagate(edge_index, size=(x.size(0), x.size(0)), x=self.lin(x))\n",
        "\n",
        "    def message(self, x_i, x_j, edge_index, size):\n",
        "        # Compute messages\n",
        "        # x_j has shape [E, out_channels]\n",
        "\n",
        "        row, col = edge_index\n",
        "        deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, out_channels]\n",
        "        return aggr_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bANNrQoh8xjF",
        "colab_type": "text"
      },
      "source": [
        "# Training setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBwQxvFY83TG",
        "colab_type": "text"
      },
      "source": [
        "We train the model in a standard way here, running it forwards to compute its predicted label distribution and backpropagating the error. Note the task setup in our graph setting: for node classification, we define a subset of nodes to be training nodes and the rest of the nodes to be test nodes, and mask out the test nodes during training via `batch.train_mask`. For graph classification, we use 80% of the graphs for training and the remainder for testing, as in other classification settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5nqB3HHoHc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, task, writer):\n",
        "    if task == 'graph':\n",
        "        data_size = len(dataset)\n",
        "        loader = DataLoader(dataset[:int(data_size * 0.8)], batch_size=64, shuffle=True)\n",
        "        test_loader = DataLoader(dataset[int(data_size * 0.8):], batch_size=64, shuffle=True)\n",
        "    else:\n",
        "        test_loader = loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(max(dataset.num_node_features, 1), 32, dataset.num_classes, task=task)\n",
        "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
        "    \n",
        "    # train\n",
        "    for epoch in range(200):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in loader:\n",
        "            print(batch.train_mask, '----')\n",
        "            opt.zero_grad()\n",
        "            embedding, pred = model(batch)\n",
        "            label = batch.y\n",
        "            if task == 'node':\n",
        "                pred = pred[batch.train_mask]\n",
        "                label = label[batch.train_mask]\n",
        "            loss = model.loss(pred, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "        total_loss /= len(loader.dataset)\n",
        "        writer.add_scalar(\"loss\", total_loss, epoch)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            test_acc = test(test_loader, model)\n",
        "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n",
        "                epoch, total_loss, test_acc))\n",
        "            writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC8IPZSOXraQ",
        "colab_type": "text"
      },
      "source": [
        "Test time, for the CiteSeer/Cora node classification task, there is only 1 graph. So we use masking to determine validation and test set.\n",
        "\n",
        "For graph classification tasks, a subset of graphs is considered validation / test graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvUBHtZaXo2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loader, model, is_validation=False):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        with torch.no_grad():\n",
        "            emb, pred = model(data)\n",
        "            pred = pred.argmax(dim=1)\n",
        "            label = data.y\n",
        "\n",
        "        if model.task == 'node':\n",
        "            mask = data.val_mask if is_validation else data.test_mask\n",
        "            # node classification: only evaluate on nodes in test set\n",
        "            pred = pred[mask]\n",
        "            label = data.y[mask]\n",
        "            \n",
        "        correct += pred.eq(label).sum().item()\n",
        "    \n",
        "    if model.task == 'graph':\n",
        "        total = len(loader.dataset) \n",
        "    else:\n",
        "        total = 0\n",
        "        for data in loader.dataset:\n",
        "            total += torch.sum(data.test_mask).item()\n",
        "    return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUo2Ve8c9wGp",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frumUA-l9zua",
        "colab_type": "text"
      },
      "source": [
        "Let's train our model and visualize its progress. First, run this snippet to generate a link to TensorBoardX, which will take you to a page where you can visualize the loss and accuracy curves of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS1dPinuyPCy",
        "colab_type": "code",
        "outputId": "d93a8e67-de4b-43b5-d47d-2c8f688ccd3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(\"./log\")\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://482f830f.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUfdqmUI-HtW",
        "colab_type": "text"
      },
      "source": [
        "Now run this snippet to start the training. When it's finished, you should be able to see its training and test performance over time on the TensorBoardX page. If you run the snippet multiple times, you will be able to see multiple training curves and compare them.\n",
        "\n",
        "We start with a graph classification task on the IMDB-BINARY dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf4-g8wT-qsj",
        "colab_type": "code",
        "outputId": "ef649c21-d54d-4e9e-f919-9f5e9dbc942e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
        "dataset = dataset.shuffle()\n",
        "task = 'graph'\n",
        "\n",
        "model = train(dataset, task, writer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://ls11-www.cs.tu-dortmund.de/people/morris/graphkerneldatasets/IMDB-BINARY.zip\n",
            "Extracting /tmp/IMDB-BINARY/IMDB-BINARY.zip\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e96183318381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'graph'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-5af95d7b8ee0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, task, writer)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'train_mask'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMeWZW8-_Eg8",
        "colab_type": "text"
      },
      "source": [
        "Here we try a node classification task on the Citeseer citation network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pREw2UQuBH4",
        "colab_type": "code",
        "outputId": "fcf468cc-7cc8-41be-8646-4f7cad651c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "dataset = Planetoid(root='/tmp/citeseer', name='citeseer')\n",
        "task = 'node'\n",
        "\n",
        "model = train(dataset, task, writer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n",
            "tensor([ True,  True,  True,  ..., False, False, False]) ----\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c58780ab21c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'node'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-5af95d7b8ee0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, task, writer)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n\u001b[1;32m     35\u001b[0m                 epoch, total_loss, test_acc))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5xf-UrHD7rp",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing node embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cESIeZB_Nqf",
        "colab_type": "text"
      },
      "source": [
        "One great quality about graph neural networks is that, like other deep methods, their hidden layers provide low-dimensional representations of our data. In the case of node classification, we get a low-dimensional representation for each node in our graph. Let's visualize the output of the last convolutional layer in our node classification GNN via TSNE, a method for plotting high-dimensional data. Nodes are colored according to their labels. We see that nodes with similar labels tend to be near each other in the embedding space, a good indication that our model has learned a useful representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i31kOOTKuLd7",
        "colab_type": "code",
        "outputId": "ee69e7ea-fe2b-4e48-8d36-6d9c389077ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "color_list = [\"red\", \"orange\", \"green\", \"blue\", \"purple\", \"brown\"]\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "embs = []\n",
        "colors = []\n",
        "for batch in loader:\n",
        "    emb, pred = model(batch)\n",
        "    embs.append(emb)\n",
        "    colors += [color_list[y] for y in batch.y]\n",
        "embs = torch.cat(embs, dim=0)\n",
        "\n",
        "xs, ys = zip(*TSNE().fit_transform(embs.detach().numpy()))\n",
        "plt.scatter(xs, ys, color=colors)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-1771b3d0e744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0membs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolor_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU6STM21EJT3",
        "colab_type": "text"
      },
      "source": [
        "# Learning unsupervised embeddings with graph autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLvR2pQSAk4H",
        "colab_type": "text"
      },
      "source": [
        "Finally, GNNs fit nicely in the framework of other neural approaches, and can be used as part of autoencoder techniques, pretraining and multitask learning methods, etc. Here we explore the idea of neural network representations further by building a graph autoencoder which learns these representations in a completely unsupervised way. In contrast to the previous example, we do not make use of the given node labels when training this representation. Instead, we encode the nodes in our network in a low-dimensional space in such a way that the embeddings can be decoded into a reconstruction of the original network. We use graph convolutional layers in the encoder.\n",
        "\n",
        "You can again use TensorBoardX here to visualize the training progress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phCgm5idq6TH",
        "colab_type": "code",
        "outputId": "cfd95379-0102-440a-bd01-497470dcdb7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(in_channels, 2 * out_channels, cached=True)\n",
        "        self.conv2 = pyg_nn.GCNConv(2 * out_channels, out_channels, cached=True)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(x, train_pos_edge_index)\n",
        "    loss = model.recon_loss(z, train_pos_edge_index)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    writer.add_scalar(\"loss\", loss.item(), epoch)\n",
        "\n",
        "def test(pos_edge_index, neg_edge_index):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model.encode(x, train_pos_edge_index)\n",
        "    return model.test(z, pos_edge_index, neg_edge_index)\n",
        "\n",
        "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "dataset = Planetoid(\"/tmp/citeseer\", \"Citeseer\", T.NormalizeFeatures())\n",
        "data = dataset[0]\n",
        "\n",
        "channels = 16\n",
        "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA availability:', torch.cuda.is_available())\n",
        "\n",
        "# encoder: written by us; decoder: default (inner product)\n",
        "model = pyg_nn.GAE(Encoder(dataset.num_features, channels)).to(dev)\n",
        "labels = data.y\n",
        "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
        "data = model.split_edges(data)\n",
        "x, train_pos_edge_index = data.x.to(dev), data.train_pos_edge_index.to(dev)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    train(epoch)\n",
        "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
        "    writer.add_scalar(\"AUC\", auc, epoch)\n",
        "    writer.add_scalar(\"AP\", ap, epoch)\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n",
            "CUDA availability: True\n",
            "Epoch: 010, AUC: 0.6453, AP: 0.7231\n",
            "Epoch: 020, AUC: 0.7695, AP: 0.7843\n",
            "Epoch: 030, AUC: 0.7950, AP: 0.8051\n",
            "Epoch: 040, AUC: 0.8226, AP: 0.8290\n",
            "Epoch: 050, AUC: 0.8220, AP: 0.8285\n",
            "Epoch: 060, AUC: 0.8175, AP: 0.8242\n",
            "Epoch: 070, AUC: 0.8254, AP: 0.8336\n",
            "Epoch: 080, AUC: 0.8362, AP: 0.8386\n",
            "Epoch: 090, AUC: 0.8387, AP: 0.8390\n",
            "Epoch: 100, AUC: 0.8363, AP: 0.8415\n",
            "Epoch: 110, AUC: 0.8357, AP: 0.8416\n",
            "Epoch: 120, AUC: 0.8378, AP: 0.8456\n",
            "Epoch: 130, AUC: 0.8410, AP: 0.8484\n",
            "Epoch: 140, AUC: 0.8489, AP: 0.8588\n",
            "Epoch: 150, AUC: 0.8503, AP: 0.8602\n",
            "Epoch: 160, AUC: 0.8470, AP: 0.8566\n",
            "Epoch: 170, AUC: 0.8456, AP: 0.8563\n",
            "Epoch: 180, AUC: 0.8437, AP: 0.8532\n",
            "Epoch: 190, AUC: 0.8426, AP: 0.8536\n",
            "Epoch: 200, AUC: 0.8412, AP: 0.8511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcSCNm-GDTtQ",
        "colab_type": "text"
      },
      "source": [
        "Finally, we plot our embeddings (the output of the encoder) with TSNE. We color each node embedding according to its label -- but note that we did not use any label information when training our encoder. Nodes with the same label are nevetheless close together in the embedding space. The model has learned the community structure without supervision!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-R_EAYAz5kk",
        "colab_type": "code",
        "outputId": "10d7eb3d-9749-4ef8-8699-11c330e5714f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model.eval()\n",
        "z = model.encode(x, train_pos_edge_index)\n",
        "colors = [color_list[y] for y in labels]\n",
        "\n",
        "xs, ys = zip(*TSNE().fit_transform(z.cpu().detach().numpy()))\n",
        "plt.scatter(xs, ys, color=colors)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEa4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd_BEZnSyyWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}